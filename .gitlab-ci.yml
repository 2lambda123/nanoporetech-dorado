include:
  - local: .gitlab/sanitizers-ci.yml

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'push' && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_PIPELINE_SOURCE == 'push'

stages:
  - pre-flight
  - build
  - test
  - deploy

variables:
  BUILD_DIR: build
  BUILD_TARGET: install
  GIT_SUBMODULE_STRATEGY: recursive
  CUDA: "11.8"
  WIN_CUDA_TOOLKIT: "/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v${CUDA}"

# Build stage components

.macos_m1_runner: &macos_m1_runner
  tags:
    - xcode-13.3.1
    - m1
  variables:
    MACOSX_DEPLOYMENT_TARGET: "12.3"

.macos_x64_runner: &macos_x64_runner
  tags:
    - osx_x86
  variables:
    MACOSX_DEPLOYMENT_TARGET: "10.15"

.linux_runner: &linux_runner
  tags:
    - linux
    - nvidia-docker

.linux_arm64_runner: &linux_arm64_runner
  tags:
    - linux_aarch64
    - docker-arm

.linux_tegra_runner: &linux_tegra_runner
  tags:
    - nvidia-docker-tegra-gpu

.linux_orin_runner: &linux_orin_runner
  tags:
    - linux-arm64-gpu
    - nvidia-docker

.windows_runner: &windows_runner
  tags:
    - windows-10
    - VS2019
    - cuda-${CUDA}

.linux_dependencies: &linux_dependencies
  before_script:
    - echo Dorado dependency stage
    - apt-get update && apt-get install -y --no-install-recommends samtools curl libhdf5-dev libssl-dev libzstd-dev libsz2 ccache
    - pip install gcovr

.run_dorado_cmake_build: &run_dorado_cmake_build
  - if [[ -d '/data/gitlab-ci-cache' ]] && [[ $OSTYPE != 'darwin'* ]] && [[ $OSTYPE != 'msys' ]]; then
  - export CCACHE_DIR=/data/gitlab-ci-cache
  - fi
  - ccache -s || true
  - cmake ${BUILD_OPTIONS} -S . -B ${BUILD_DIR}
  - cmake --build ${BUILD_DIR} --config Release --target ${BUILD_TARGET} -j 8

.run_dorado_cmake_ctest: &run_dorado_cmake_ctest
  - ctest -C Release --test-dir ${BUILD_DIR} --output-on-failure --verbose

.build_dorado: &build_dorado
  stage: build
  script:
    - echo Dorado build stage
    - echo "BUILD_OPTIONS '${BUILD_OPTIONS}'"
    - *run_dorado_cmake_build
    - *run_dorado_cmake_ctest
  artifacts:
    paths:
      - dist
      - tests/*.sh
      - tests/*.bat
      - tests/data
    expire_in: 1 day
  interruptible: true

.build_dorado_archive: &build_dorado_archive
  stage: build
  script:
    - if [[ -d '/data/gitlab-ci-cache' ]] && [[ $OSTYPE != 'darwin'* ]] && [[ $OSTYPE != 'msys' ]]; then
    - export CCACHE_DIR=/data/gitlab-ci-cache
    - fi
    - ccache -s || true  
    - cmake ${BUILD_OPTIONS} -S . -B ${BUILD_DIR}
    - cmake --build ${BUILD_DIR} --config Release -j 8
    - cpack --config ${BUILD_DIR}/CPackConfig.cmake
  artifacts:
    paths:
      - archive
    expire_in: 1 day
  interruptible: true

.build_dorado_lib_only: &build_dorado_lib_only
  stage: build
  script:
    - cmake ${BUILD_OPTIONS} -S . -B ${BUILD_DIR} -DDORADO_LIB_ONLY=1
    - cmake --build ${BUILD_DIR} -j 8
  interruptible: true

.sign_dorado:macos:
  script:
    # Older versions of macOS (10.15) can't run notarytool through xcrun, but can make
    # use of the standalone notarytool executable if it's copied from a newer system.
    # See https://developer.apple.com/forums/thread/712665.
    - |
      if command -v notarytool > /dev/null; then
        NOTARYTOOL=(notarytool)
      else
        NOTARYTOOL=(xcrun notarytool)
      fi
    # We sign the executable as part of CPack's packaging steps, so the package that it
    # produces should be ready to be notarized. That can be done asynchronously, but
    # doing everything in one pass (--wait flag) saves complicating the jobs.
    - ${NOTARYTOOL[@]} submit archive/dorado-*.zip
        --apple-id ${APPLE_NOTARIZATION_ID}
        --password ${APPLE_NOTARIZATION_PASSWORD}
        --team-id ${APPLE_NOTARIZATION_TEAM}
        --progress --verbose --wait
    # If notarization fails you need to run `xcrun notarytool log <request id>` to get
    # information about what failed.
    #
    # Extract the binary and check that it's notarized, since notarytool doesn't appear
    # to return an error on failure.
    - rm -rf notarization_check
    - unzip archive/dorado-*.zip -d notarization_check
    - spctl -a -t install -vvvv notarization_check/dorado-*/bin/dorado
    #
    # No stapling for now since you can only staple packages and not executables, hence
    # we'd need to switch to a dmg instead and do something like:
    #- xcrun stapler staple dorado-*.dmg

# Pre-flight stages

pre-commit:
  image: ${DORADO_PRECOMMIT}
  variables:
    GIT_SUBMODULE_STRATEGY: none
  stage: pre-flight
  script:
    - pip install pre-commit
    - pre-commit run --all-files
  tags:
    - linux
  interruptible: true

# Build stages

build:linux:x86:focal:install_deps:
  image: ${DORADO_DOCKER_ROOT}/dorado-no-deps-20.04-cuda-${CUDA}.0:1.0
  <<: *linux_dependencies
  <<: *linux_runner
  <<: *build_dorado
  when: manual

build:linux:x86:focal:
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-20.04-cuda-${CUDA}.0:1.1
  variables:
    BUILD_OPTIONS: "-DBUILD_KOI_FROM_SOURCE=ON -DGITLAB_CI_TOKEN=${CI_JOB_TOKEN} -DONT_MM2_EXE=ON"
  <<: *linux_runner
  <<: *build_dorado

build:linux:x86:focal_coverage:
  stage: build
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-20.04-cuda-${CUDA}.0:1.1
  variables:
    BUILD_OPTIONS: "-DGITLAB_CI_TOKEN=${CI_JOB_TOKEN} -DGENERATE_TEST_COVERAGE=1"
    BUILD_TARGET: "dorado_test_coverage"
  <<: *linux_dependencies
  <<: *linux_runner
  script:
    - *run_dorado_cmake_build
  rules:
      - if: $CI_PIPELINE_SOURCE == "schedule"
  artifacts:
    paths:
      - build/dorado_test_coverage/*

build:linux:arm64:bionic:
  image: ${DORADO_DOCKER_ROOT}/dorado-l4t-r32.4.3-deps:1.1
  variables:
    BUILD_OPTIONS: "-DONT_MM2_EXE=ON"
  <<: *linux_arm64_runner
  <<: *build_dorado

build:linux:arm64:focal:
  image: nvcr.io/nvidia/l4t-pytorch:r35.1.0-pth1.13-py3
  variables:
    BUILD_OPTIONS: "-DONT_MM2_EXE=ON"
  <<: *linux_dependencies
  <<: *linux_arm64_runner
  <<: *build_dorado

build:linux:x86:focal_koi_download:
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-20.04-cuda-${CUDA}.0:1.1
  <<: *linux_runner
  <<: *build_dorado

build:windows:
  <<: *windows_runner
  <<: *build_dorado
  before_script:
    - export PATH=${PATH}:${PWD}/dist/bin
    - export CUDA_TOOLKIT=$(cygpath -u $(cygpath -d "${WIN_CUDA_TOOLKIT}"))
    - export BUILD_OPTIONS="-A x64 -T cuda=${CUDA} -DCUDAToolkit_ROOT=${CUDA_TOOLKIT} -DBUILD_KOI_FROM_SOURCE=ON -DGITLAB_CI_TOKEN=${CI_JOB_TOKEN}"
    - echo BUILD_OPTIONS is ${BUILD_OPTIONS}

build:windows_koi_download:
  <<: *windows_runner
  <<: *build_dorado
  before_script:
    - export PATH=${PATH}:${PWD}/dist/bin
    - export CUDA_TOOLKIT=$(cygpath -u $(cygpath -d "${WIN_CUDA_TOOLKIT}"))
    - export BUILD_OPTIONS="-A x64 -T cuda=${CUDA} -DCUDAToolkit_ROOT=${CUDA_TOOLKIT}"
    - echo BUILD_OPTIONS is ${BUILD_OPTIONS}

build:macos:m1:
  before_script:
    - export BUILD_OPTIONS="-DONT_MM2_EXE=ON"
  <<: *macos_m1_runner
  <<: *build_dorado

build:macos:x64:
  before_script:
    - export BUILD_OPTIONS="-DONT_MM2_EXE=ON"
  <<: *macos_x64_runner
  <<: *build_dorado

build:ios:m1:
  variables:
    BUILD_OPTIONS: "-DCMAKE_TOOLCHAIN_FILE=cmake/ios-cmake/ios.toolchain.cmake -DPLATFORM=OS64 -DSKIP_HDF_PLUGINS=1 -DDEPLOYMENT_TARGET=16.0"
  <<: *macos_m1_runner
  <<: *build_dorado_lib_only

build_archive:linux:x86:focal:
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-20.04-cuda-${CUDA}.0:1.1
  variables:
    BUILD_OPTIONS: "-DBUILD_KOI_FROM_SOURCE=ON -DGITLAB_CI_TOKEN=${CI_JOB_TOKEN}"
  <<: *linux_runner
  <<: *build_dorado_archive
  when: manual

build_archive:linux:x86:cuda12:
  image: nvcr.io/nvidia/pytorch:23.01-py3
  variables:
    BUILD_OPTIONS: "-DDORADO_LIBTORCH_DIR=/usr/local/lib/python3.8/dist-packages/torch"
  <<: *linux_dependencies
  <<: *linux_runner
  <<: *build_dorado_archive
  when: manual

build_archive:linux:arm64:bionic:
  image: ${DORADO_DOCKER_ROOT}/dorado-l4t-r32.4.3-deps:1.1
  <<: *linux_arm64_runner
  <<: *build_dorado_archive
  when: manual

build_archive:linux:arm64:focal:
  image: nvcr.io/nvidia/l4t-pytorch:r35.1.0-pth1.13-py3
  <<: *linux_dependencies
  <<: *linux_arm64_runner
  <<: *build_dorado_archive
  when: manual

build_archive:linux:x86:centos7:
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-centos7-cuda-${CUDA}.0:1.1
  variables:
    BUILD_OPTIONS: "-DBUILD_KOI_FROM_SOURCE=ON -DGITLAB_CI_TOKEN=${CI_JOB_TOKEN} -DDORADO_USING_OLD_CPP_ABI=ON -DDYNAMIC_HDF=ON"
  <<: *linux_runner
  <<: *build_dorado_archive
  when: manual

build_archive:windows:
  before_script:
    - export CUDA_TOOLKIT=$(cygpath -u $(cygpath -d "${WIN_CUDA_TOOLKIT}"))
    - export BUILD_OPTIONS="-A x64 -T cuda=${CUDA} -DCUDAToolkit_ROOT=${CUDA_TOOLKIT} -DBUILD_KOI_FROM_SOURCE=ON -DGITLAB_CI_TOKEN=${CI_JOB_TOKEN}"
    - echo BUILD_OPTIONS is ${BUILD_OPTIONS}
  <<: *windows_runner
  <<: *build_dorado_archive
  when: manual

build_archive:macos:m1:
  extends:
    - .macos_m1_runner
    - .build_dorado_archive
  script:
    - !reference [.build_dorado_archive, script]
    - !reference [.sign_dorado:macos, script]
  when: manual

build_archive:macos:x64:
  extends:
    - .macos_x64_runner
    - .build_dorado_archive
  script:
    - !reference [.build_dorado_archive, script]
    # Signing on x64 disabled for now since our CI machines are on 10.15.
    # See https://developer.apple.com/forums/thread/712665.
    #- !reference [.sign_dorado:macos, script]
  when: manual

# Test stage components

.test_dorado: &test_dorado
  stage: test
  variables:
    GIT_STRATEGY: none
    MODEL: dna_r10.4.1_e8.2_400bps_hac@v4.1.0
    BATCH: 384
  script:
    - bash ./tests/test_simple_basecaller_execution.sh ./dist/bin/dorado ${MODEL} ${BATCH}
    - bash ./tests/test_expected_logging.sh ./dist/bin/dorado ${MODEL} ${BATCH}
  interruptible: true

.test_dorado_windows: &test_dorado_windows
  stage: test
  variables:
    GIT_STRATEGY: none
  script:
    - .\\tests\\test_simple_basecaller_execution.bat .\\dist\\bin\\dorado.exe
  interruptible: true

.test_archive: &test_archive
  stage: test
  variables:
    GIT_STRATEGY: none
  script:
    - tar -xzf archive/dorado-*.gz
    - ldd ./dorado-*/bin/dorado
    - if [ -e ./dorado-*/lib/libdorado_torch_lib.so ]; then ldd ./dorado-*/lib/libdorado_torch_lib.so; fi
    # We just want to check that dorado will run here, so simply display the verbose version info
    - ./dorado-*/bin/dorado -vv
  interruptible: true

# Test stages

test:windows:
  <<: *windows_runner
  <<: *test_dorado_windows
  needs:
    - build:windows

test:linux:x86:focal:
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-20.04-cuda-${CUDA}.0:1.1
  <<: *linux_dependencies
  <<: *linux_runner
  <<: *test_dorado
  needs:
    - build:linux:x86:focal
  artifacts:
    when: on_failure
    paths:
      - tests
    expire_in: 1 day

test:linux:arm64:bionic:
  image: ${DORADO_DOCKER_ROOT}/dorado-l4t-r32.4.3-deps:1.1
  <<: *linux_dependencies
  <<: *linux_tegra_runner
  <<: *test_dorado
  variables:
    GIT_STRATEGY: none
    MODEL: dna_r10.4.1_e8.2_400bps_hac@v4.1.0
    BATCH: 0
  needs:
    - build:linux:arm64:bionic

test:linux:arm64:focal:
  image: nvcr.io/nvidia/l4t-pytorch:r35.1.0-pth1.13-py3
  <<: *linux_dependencies
  <<: *linux_orin_runner
  <<: *test_dorado
  needs:
    - build:linux:arm64:focal

test:macos:m1:
  <<: *macos_m1_runner
  <<: *test_dorado
  needs:
    - build:macos:m1

test:macos:x64:
  <<: *macos_x64_runner
  <<: *test_dorado
  needs:
    - build:macos:x64
  variables:
    GIT_STRATEGY: none
    MODEL: dna_r10.4.1_e8.2_400bps_fast@v4.1.0
    BATCH: 0

# Test that you can run dorado in a clean cuda 20.04 environment
test_archive:linux:x86:20.04_nvidia:
  image: nvidia/cuda:${CUDA}.0-devel-ubuntu20.04
  <<: *linux_runner
  <<: *test_archive
  needs:
    - build_archive:linux:x86:centos7

# Test that you can run dorado in a clean cpu 18.04 environment
test_archive:linux:x86:18.04:
  image: ${DORADO_DOCKER_EXT}/ubuntu:18.04
  <<: *linux_runner
  <<: *test_archive
  needs:
    - build_archive:linux:x86:centos7

# Test that you can run dorado in a clean cpu 20.04 environment
test_archive:linux:x86:20.04:
  image: ${DORADO_DOCKER_EXT}/ubuntu:20.04
  <<: *linux_runner
  <<: *test_archive
  needs:
    - build_archive:linux:x86:centos7

# Test that you can run dorado in a clean l4t environment
test_archive:linux:arm64:18.04:
  image: nvcr.io/nvidia/l4t-base:r32.4.3
  <<: *linux_tegra_runner
  <<: *test_archive
  needs:
    - build_archive:linux:arm64:bionic

test_archive:linux:arm64:20.04:
  image: nvcr.io/nvidia/l4t-pytorch:r35.1.0-pth1.13-py3
  <<: *linux_dependencies
  <<: *linux_orin_runner
  <<: *test_archive
  needs:
    - build_archive:linux:arm64:focal

# Test that models can be downloaded and run.
test:model_download:linux:x86:focal:
  image: ${DORADO_DOCKER_ROOT}/dorado-deps-20.04-cuda-${CUDA}.0:1.1
  <<: *linux_dependencies
  <<: *linux_runner
  stage: test
  needs:
    - build:linux:x86:focal
  script:
    - ./tests/test_model_download.py --exe ./dist/bin/dorado --data ./tests/data
  interruptible: true
  rules:
      - if: $CI_PIPELINE_SOURCE == "schedule"
      - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH
        when: manual
        # See https://forum.gitlab.com/t/specifying-a-pipeline-step-as-manual-causes-its-status-to-always-be-blocked/58333/3
        allow_failure: true


# MLHub

.mlhub: &mlhub
  stage: test
  when: manual
  image: ${TRIGGER_IMAGE}
  needs: []
  variables:
    GIT_STRATEGY: none
  interruptible: true

# MLHub - Single read eval
.mlhub_sre:
  <<: *mlhub
  script:
    - echo ${MODELS}
    - |
      curl -i --header "Content-Type: application/json" \
      --request POST \
      --data '{
          "key": "'${MLHUB_TRIGGER_SRE}'",
          "job_name": "Dorado SRE: '${CONDITION}' '${CI_COMMIT_REF_NAME}' - '"$CI_COMMIT_TITLE"' ",
          "script_parameters": {
              "models":'${MODELS}',
              "duplex_models":'${DUPLEX_MODELS}',
              "sre_output":"'${SRE_OUTPUT_ROOT}'/'${CI_COMMIT_SHA}'/",
              "sre_config":"${projectDir}/configs/'${SRE_CONFIG}'",
              "dorado_branch":"'${CI_COMMIT_SHA}'",
              "dorado_exe":""
              }
      }' \
      ${MLHUB_TRIGGER_URL}

mlhub:sre_4k_260bps:
  extends:
    .mlhub_sre
  variables:
    CONDITION: '4k_260bps'
    SRE_CONFIG: "dna_r10.4.1-e8.2-4khz-260bps-prom.json"
    MODELS: '["dna_r10.4.1_e8.2_260bps_fast@v4.1.0","dna_r10.4.1_e8.2_260bps_hac@v4.1.0","dna_r10.4.1_e8.2_260bps_sup@v4.1.0"]'
    DUPLEX_MODELS: '[]'

mlhub:sre_4k_400bps:
  extends:
    .mlhub_sre
  variables:
    CONDITION: '4k_400bps'
    SRE_CONFIG: "dna_r10.4.1-e8.2-4khz-400bps-prom.json"
    MODELS: '["dna_r10.4.1_e8.2_400bps_fast@v4.1.0","dna_r10.4.1_e8.2_400bps_hac@v4.1.0","dna_r10.4.1_e8.2_400bps_sup@v4.1.0"]'
    DUPLEX_MODELS: '[]'

mlhub:sre_5k_400bps:
  extends:
    .mlhub_sre
  variables:
    CONDITION: '5k_400bps'
    SRE_CONFIG: "dna_r10.4.1-e8.2-5khz-400bps-prom.json"
    MODELS: '["dna_r10.4.1_e8.2_400bps_fast@v4.2.0","dna_r10.4.1_e8.2_400bps_hac@v4.2.0","dna_r10.4.1_e8.2_400bps_sup@v4.2.0"]'
    DUPLEX_MODELS: '[]'

mlhub:sre_5k_400bps_duplex:
  extends:
    .mlhub_sre
  variables:
    CONDITION: '5k_400bps_duplex'
    SRE_CONFIG: "dna_r10.4.2-e8.2-5khz-400bps-prom.json"
    MODELS: '["dna_r10.4.1_e8.2_400bps_hac@v4.2.0","dna_r10.4.1_e8.2_400bps_sup@v4.2.0"]'
    DUPLEX_MODELS: '["dna_r10.4.1_e8.2_5khz_stereo@v1.1"]'

# MLHub - Remora
mlhub:remora-validate:
  <<: *mlhub
  script:
    - |
      curl --header "Content-Type: application/json" \
      --request POST \
      --data '{
          "key": "'${MLHUB_TRIGGER_KEY_REMORA}'",
          "job_name": "Dorado Remora: '${CI_COMMIT_REF_NAME}' - '"$CI_COMMIT_TITLE"' ",
          "script_parameters": {
            "dorado_branch":"'${CI_COMMIT_SHA}'",
            "dorado_build_options":"",
            "dorado_build_threads":"-- -j 8",
            "dorado_device":"'${DEVICE}'",
            "dorado_model":"dna_r10.4.1_e8.2_400bps_hac@v4.0.0",
            "dorado_modbase_model":"dna_r10.4.1_e8.2_400bps_hac@v4.0.0_5mCG_5hmCG@v2",
            "remora_model":"/media/groups/machine_learning/active/rharris/shared/nf-dorado-remora-analysis_datasets/dna_r10.4.1_e8.2_400bps_hac_v4.0.0_5hmc_5mc_CG_v2.pt"
          }
      }' \
      ${MLHUB_TRIGGER_URL}
  parallel:
    matrix:
      - DEVICE: 
        - "cuda:all"
        - "cpu"

# MLHub - Dorado integration test
mlhub:dorado-integration-tests:
  <<: *mlhub
  script:
    - |
      curl --header "Content-Type: application/json" \
      --request POST \
      --data '{
          "key": "'${MLHUB_TRIGGER_KEY_DORADO_INTEGRATION_TEST}'",
          "job_name": "dorado-integration-test : '${CI_COMMIT_REF_NAME}'",
          "script_parameters": {
            "dorado_branch":"'${CI_COMMIT_SHA}'",
            "dorado_build_options":"",
            "prompt_clean_basecalls": true,
            "dorado_exe": "",
            "config": "'${DORADO_INTEGRATION_TEST_MLHUB_CONFIG}'"
          }
      }' \
      ${MLHUB_TRIGGER_URL}
  rules:
      - if: $CI_PIPELINE_SOURCE == "schedule"
      - if: $CI_PIPELINE_SOURCE == "push"
        when: manual
        allow_failure: true

# Deploy

deploy:all:
  stage: deploy
  variables:
    GIT_STRATEGY: none
  script:
   - ls -lh archive
  when: manual
  artifacts:
    paths:
      - archive
    expire_in: 1 day
  needs:
    - build_archive:linux:x86:centos7
    - build_archive:linux:arm64:bionic
    - build_archive:linux:arm64:focal
    - build_archive:macos:m1
    - build_archive:macos:x64
    - build_archive:windows
